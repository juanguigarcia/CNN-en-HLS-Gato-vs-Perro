# -*- coding: utf-8 -*-
"""PerrosVsGatos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RXs1AvDScraPGZxOBbKV3SubCz2tYRSF
"""

#Montamos y habilitamos acceso a nuestro Google Drive
from google.colab import drive
drive.mount('/content/gdrive',force_remount=True)

import tensorflow as tf
import tensorflow_datasets as tfds

datos, metadatos = tfds.load('cats_vs_dogs', as_supervised=True, with_info=True)

tfds.as_dataframe(datos['train'].take(5), metadatos)

#Manipular y visualizar el set
#Lo pasamos a TAMANO_IMG (100x100) y a blanco y negro (solo para visualizar)
import matplotlib.pyplot as plt
import cv2

plt.figure(figsize=(20,20))

TAMANO_IMG=100

for i, (imagen, etiqueta) in enumerate(datos['train'].take(25)):
  imagen = cv2.resize(imagen.numpy(), (TAMANO_IMG, TAMANO_IMG))
  imagen = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)
  plt.subplot(5, 5, i+1)
  plt.xticks([])
  plt.yticks([])
  plt.imshow(imagen, cmap='gray')

#Variable que contendra todos los pares de los datos (imagen y etiqueta) ya modificados (blanco y negro, 100x100)
datos_entrenamiento = []

for i, (imagen, etiqueta) in enumerate(datos['train']): #Todos los datos
  imagen = cv2.resize(imagen.numpy(), (TAMANO_IMG, TAMANO_IMG))
  imagen = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)
  imagen = imagen.reshape(TAMANO_IMG, TAMANO_IMG, 1) #Cambiar tamano a 100,100,1
  datos_entrenamiento.append([imagen, etiqueta])

#Preparar mis variables X (entradas) y y (etiquetas) separadas

X = [] #imagenes de entrada (pixeles)
y = [] #etiquetas (perro o gato)

for imagen, etiqueta in datos_entrenamiento:
  X.append(imagen)
  y.append(etiqueta)

#Normalizar los datos de las X (imagenes). Se pasan a numero flotante y dividen entre 255 para quedar de 0-1 en lugar de 0-255
import numpy as np

X = np.array(X).astype(float) / 255

y = np.array(y)

modeloCNN = tf.keras.models.Sequential([
  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(100, 100, 1)),
  tf.keras.layers.MaxPooling2D(2, 2),
  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
  tf.keras.layers.MaxPooling2D(2, 2),
  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
  tf.keras.layers.MaxPooling2D(2, 2),

  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(100, activation='relu'),
  tf.keras.layers.Dense(1, activation='sigmoid')
])

modeloCNN.compile(optimizer='adam',
                    loss='binary_crossentropy',
                    metrics=['accuracy'])

from tensorflow.keras.callbacks import TensorBoard
tensorboardCNN = TensorBoard(log_dir='logs/cnn')
history = modeloCNN.fit(
    X, y,
    batch_size=32,
    validation_split=0.15,
    epochs=100,
    callbacks=[tensorboardCNN]
)

import matplotlib.pyplot as plt

# Extraer datos del historial
loss = history.history['loss']
val_loss = history.history['val_loss']
accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']

# Graficar la función de pérdida
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.title('Loss over epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()


# Graficar la función de precisión
plt.subplot(1, 2, 2)
plt.plot(accuracy, label='Training Accuracy')
plt.plot(val_accuracy, label='Validation Accuracy')
plt.title('Accuracy over epochs')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.tight_layout()
plt.savefig('loss_accuracy_plot.png')  # Guarda la gráfica como 'loss_plot.png'
plt.show()

modeloCNN.save('perros-gatos-cnn.keras')


!cp /content/perros-gatos-cnn.keras /content/gdrive/MyDrive/TrabajoSEI
!cp /content/loss_accuracy_plot.png /content/gdrive/MyDrive/TrabajoSEI

import tensorflow as tf
import numpy as np

# Cargar el modelo entrenado
model = tf.keras.models.load_model('perros-gatos-cnn.keras')

# Función para exportar pesos y sesgos a un archivo C
def export_to_c(weights, biases, layer_name, filename):
    with open(filename, 'w') as f:
        f.write(f"#ifndef {layer_name.upper()}_H\n")
        f.write(f"#define {layer_name.upper()}_H\n\n")

        f.write(f"// Pesos para la capa {layer_name}\n")
        f.write(f"float {layer_name}_weights[] = {{\n")
        f.write(",\n".join(map(str, weights.flatten())))
        f.write("\n};\n\n")

        f.write(f"// Sesgos para la capa {layer_name}\n")
        f.write(f"float {layer_name}_biases[] = {{\n")
        f.write(",\n".join(map(str, biases)))
        f.write("\n};\n\n")

        f.write(f"#endif // {layer_name.upper()}_H\n")

# Extraer pesos y sesgos para cada capa
for i, layer in enumerate(model.layers):
    if 'conv2d' in layer.name or 'dense' in layer.name:
        weights, biases = layer.get_weights()
        layer_name = layer.name
        filename = f"{layer_name}.h"
        export_to_c(weights, biases, layer_name, filename)
        print(f"Pesos y sesgos exportados para {layer_name}: {filename}")

!cp /content/conv2d.h /content/gdrive/MyDrive/TrabajoSEI
!cp /content/conv2d_1.h /content/gdrive/MyDrive/TrabajoSEI
!cp /content/conv2d_2.h /content/gdrive/MyDrive/TrabajoSEI
!cp /content/dense.h /content/gdrive/MyDrive/TrabajoSEI
!cp /content/dense_1.h /content/gdrive/MyDrive/TrabajoSEI